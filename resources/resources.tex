\documentclass{article}

\begin{document}

\section{Resources}

In this section, we keep a record of the important resources used to investigate the current state of the art resource in distributed neural network training.

\subsection{MapReduce Based Parallel Neural Networks in Enabling Large Scale Machine Learning}

In this paper, the authors explore the use of MapReduce clusters to parallelize neural networks.

\begin{itemize}

    \item MRBPNN 1 uses a classic scenario where each compute instance in the MapReduce cluster is given the same neural network. Its weird however that they don't describe how the instances share gradient information.

    \item MRBPNN 2 uses a ensemble technique to maintain a classifcation accuracy among several weak classifiers.
    
\end{itemize}


https://www.hindawi.com/journals/cin/2015/297672/

\end{document}